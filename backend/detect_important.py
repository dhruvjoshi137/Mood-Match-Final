# -*- coding: utf-8 -*-
"""Detect_Important.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10sqAouUSJtmlx6ts_anJbqrjFu4-ePWr
"""

import os
import re
import json
import copy
import time
import datetime
import requests
import spacy
from PIL import Image, ImageDraw, ImageFont, ImageOps
import matplotlib.pyplot as plt
from spacy.matcher import Matcher
from io import BytesIO
from sklearn.neighbors import KDTree
from selenium import webdriver
import tempfile
# from IPython.display import display  # Notebook only, comment out for backend
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from pexels_api import API as PexelsAPI
import random
from PIL import ImageColor
from selenium.webdriver.common.by import By
from webdriver_manager.core.os_manager import ChromeType
from googleapiclient.discovery import build

with open("colour.json", "r") as f:
    color_data = json.load(f)

with open("emotion_design_dataset.json", "r") as f:
    emotion_dataset = json.load(f)

template_bg = Image.open("Blank Template.png").convert("RGB")
template_bg = template_bg.resize((1080, 1620))

try:
    nlp = spacy.load("en_core_web_sm")
except:
    import spacy.cli
    spacy.cli.download("en_core_web_sm")
    nlp = spacy.load("en_core_web_sm")

matcher = Matcher(nlp.vocab)
matcher.add("IMPLICIT_COLOR_NOUN_COLOR", [[{"POS": "NOUN"}, {"LOWER": "color"}]])
matcher.add("IMPLICIT_COLOR_COLOR_OF_NOUN", [[{"LOWER": "color"}, {"LOWER": "of"}, {"POS": "DET", "OP": "?"}, {"POS": "NOUN"}]])

color_keywords = [c.lower() for colors in color_data.values() for c in colors]
NEGATION_WORDS = {"not", "no", "without", "except"}
NEGATION_PREFIXES = {"un", "non", "dis", "a"}
NEGATIVE_ADJ = {"unfriendly", "unpleasant", "ugly", "unattractive"}
EXCLUSION_VERBS = {"exclude", "remove", "omit", "avoid", "prevent"}

layout_keywords = {
    "grid": ["grid layout", "uniform grid"],
    "irregular": ["scattered", "random", "asymmetrical"],
    "minimal": ["minimal", "minimalist", "simple", "clean"],
    "centered": ["centered", "aligned center", "symmetrical"],
    "rounded": ["rounded corners", "soft edges"],
    "sharp": ["sharp edges", "boxy", "straight corners"],
    "split": ["split view", "side by side", "dual layout"]
}

def run(emotion_label, color_data, emotion_dataset, template_bg):

    api_key = "Avn6UtTXyYNcle6Kr4J0o9fKEKt3BERVfCqxMUqOWoqIuyaHB25OsRt6"

    # NLP Setup
    nlp = initialize_nlp()
    matcher = Matcher(nlp.vocab)
    matcher.add("IMPLICIT_COLOR_NOUN_COLOR", [[{"POS": "NOUN"}, {"LOWER": "color"}]])
    matcher.add("IMPLICIT_COLOR_COLOR_OF_NOUN", [[{"LOWER": "color"}, {"LOWER": "of"}, {"POS": "DET", "OP": "?"}, {"POS": "NOUN"}]])
    matcher.add("IMPLICIT_COLOR_SHADE_OF", [[{"LOWER": {"IN": ["shade", "tone", "hue", "tint"]}}, {"LOWER": "of"}, {"POS": "DET", "OP": "?"}, {"POS": "NOUN"}]])

    # Vocabulary Prep
    color_keywords = [c.lower() for group in color_data.values() for c in group]
    pattern_keywords = ["floral", "stripes", "polka dots", "abstract", "geometric", "waves"]

    sanitized_label = sanitize_emotion_label(emotion_label)
    session_dir = tempfile.mkdtemp()
    print(f"Session assets will be stored in: {session_dir}")

    font_paths = font(emotion_label)
    prompt = input("Enter a visual prompt: ").strip()

    parsed = parse_prompt(prompt, nlp, matcher, color_keywords, pattern_keywords)
    print("Parsed result:")
    print(json.dumps(parsed, indent=2))

    # Fallback Handling
    if is_prompt_generic(parsed):
        moodboard_file = emotion_dataset.get(sanitized_label, {}).get("moodboard")
        if moodboard_file:
            moodboard_path = os.path.join("default_ui", moodboard_file)
            if os.path.exists(moodboard_path):
                output_path = os.path.join(session_dir, "moodboard_default.png")
                Image.open(moodboard_path).save(output_path)
                print(f"Fallback moodboard saved to: {output_path}")
                # display(Image(filename=output_path, width=300))  # Notebook only
            else:
                print(f"Fallback moodboard '{moodboard_file}' not found.")
        else:
            print(f"No fallback moodboard found for '{sanitized_label}'")
        return None

    # Moodboard Spec & Rendering
    spec = merge_prompt_with_spec(parsed, emotion_dataset, sanitized_label)
    spec["font_paths"] = font_paths
    spec = image(spec, emotion_label, api_key)

    canvas_bg = template_bg.copy()
    output_img = moodboard(spec, emotion_label, canvas_bg, emotion_dataset)
    output_path = os.path.join(session_dir, "moodboard.png")
    output_img.save(output_path)
    print(f"Moodboard saved to: {output_path}")
    # display(Image(filename=output_path, width=300))  # Notebook only

    return spec, emotion_label, template_bg, emotion_dataset, session_dir

pattern_keywords = ["floral", "stripes", "polka dots", "abstract", "geometric", "waves"]


def initialize_nlp():
    global spacy
    try:
        return spacy.load("en_core_web_sm")
    except OSError:
        import spacy.cli
        spacy.cli.download("en_core_web_sm")
        return spacy.load("en_core_web_sm")

def is_negated(span):
    if isinstance(span, spacy.tokens.Doc): span = span[:]
    if any(token.dep_ == "neg" for token in span): return True
    if span.start > 0 and span.doc[span.start - 1].lower_ in NEGATION_WORDS: return True
    for token in span:
        if token.text.lower() in NEGATIVE_ADJ: return True
        if token.dep_ in {"dobj", "nsubjpass", "pobj"} and token.head.lemma_ in EXCLUSION_VERBS: return True
        for ancestor in token.ancestors:
            if ancestor.lemma_ in EXCLUSION_VERBS and token.dep_ in {"dobj", "nsubjpass", "pobj"}: return True
        for prefix in NEGATION_PREFIXES:
            if token.text.lower().startswith(prefix) and token.pos_ in {"ADJ", "NOUN"}: return True
    return False

def adjust_negation_contrast(color_candidates, doc, nlp):
    found, negated = set(), set()
    for phrase in color_candidates:
        span = nlp(phrase)
        if is_negated(span): negated.add(phrase)
        else: found.add(phrase)
    for i, token in enumerate(doc):
        if token.lower_ == "not":
            left_span = doc[max(i - 6, 0):i].text
            right_span = doc[i + 1:i + 7].text
            for phrase in color_candidates:
                if phrase in left_span: found.add(phrase)
                elif phrase in right_span: negated.add(phrase)
    unassigned = set(color_candidates) - found - negated
    found |= unassigned
    return sorted(found), sorted(negated)

def parse_prompt(prompt, nlp=None, matcher=None, color_keywords=None, pattern_keywords=None):
    # Initialize defaults if not provided
    if nlp is None:
        nlp = initialize_nlp()
    if matcher is None:
        matcher = Matcher(nlp.vocab)
        matcher.add("IMPLICIT_COLOR_NOUN_COLOR", [[{"POS": "NOUN"}, {"LOWER": "color"}]])
        matcher.add("IMPLICIT_COLOR_COLOR_OF_NOUN", [[{"LOWER": "color"}, {"LOWER": "of"}, {"POS": "DET", "OP": "?"}, {"POS": "NOUN"}]])
    if color_keywords is None:
        color_keywords = [c.lower() for colors in color_data.values() for c in colors]
    if pattern_keywords is None:
        pattern_keywords = ["floral", "stripes", "polka dots", "abstract", "geometric", "waves"]
    
    doc = nlp(prompt.lower())
    explicit_found, explicit_negated, color_phrases = [], [], []

    for i in range(len(doc) - 1):
        if doc[i].pos_ == "ADJ" and doc[i + 1].text in color_keywords:
            phrase = f"{doc[i].text} {doc[i + 1].text}"
            color_phrases.append(phrase)

    matches = matcher(doc)
    for _, start, end in matches:
        span = doc[start:end]
        color_phrases.append(span.text.strip())

    for color_phrase in color_keywords:
        pattern = r'\b' + re.escape(color_phrase) + r'\b'
        for match in re.finditer(pattern, doc.text):
            span = doc.char_span(*match.span(), alignment_mode="expand")
            if span:
                if is_negated(span): explicit_negated.append(span.text)
                else: explicit_found.append(span.text)

    for phrase in color_phrases:
        if phrase not in explicit_found and phrase not in explicit_negated:
            explicit_found.append(phrase)

    all_candidates = list(set(explicit_found + explicit_negated))
    found_colors, negated_colors = adjust_negation_contrast(all_candidates, doc, nlp)

    visuals = []
    abstract_terms = {"mood", "emotion", "silence", "quietness", "gentle", "soft", "subtle", "neutral", "neutrals", "calm", "dark", "light"}
    for sent in doc.sents:
        parts = re.split(r"[,\-–—]", sent.text)
        for phrase in parts:
            phrase = phrase.strip()
            tokens = re.findall(r"\b\w+\b", phrase.lower())
            is_abstract = any(t in abstract_terms or t in color_keywords for t in tokens)
            if len(tokens) >= 2 and not is_abstract and not is_negated(nlp(phrase)):
                visuals.append(phrase)

    patterns = [kw for kw in pattern_keywords if re.search(r'\b' + re.escape(kw) + r'\b', doc.text) and not is_negated(nlp(kw))]

    return {
        "colors": sorted(set(found_colors)),
        "negated_colors": sorted(set(negated_colors)),
        "visuals": visuals,
        "patterns": patterns
    }




def merge_prompt_with_spec(parsed_data, emotion_dataset, label):

    # Defensive: always set required keys with defaults if missing
    base = copy.deepcopy(emotion_dataset.get(label, {}))
    if not base:
        print(f"Warning: Emotion label '{label}' not found in dataset. Using empty base.")
        base = { "colors": [], "images_keywords": [], "pattern": "", "fonts": {}, "samples": {}, "font_bg_color": "#FFFFFF", "font_color": "#000000" }

    # Defensive: ensure all required keys exist
    base.setdefault("colors", [])
    base.setdefault("images_keywords", [])
    base.setdefault("pattern", "")
    base.setdefault("fonts", {"headings": "Open Sans", "body_text": "Open Sans", "highlight_text": "Open Sans"})
    base.setdefault("samples", {"headings": "Regular", "body_text": "Regular", "highlight_text": "Regular"})
    base.setdefault("font_bg_color", "#FFFFFF")
    base.setdefault("font_color", "#000000")
    base.setdefault("image_paths", ["Blank Template.png"]*4)
    base.setdefault("pattern_path", "Blank Template.png")

    parsed_colors = parsed_data.get("colors", [])
    if parsed_colors and isinstance(parsed_colors[0], dict):
        base["colors"] = parsed_colors

    abstract_terms = {
        "texture", "pattern", "emotion", "tone", "feeling", "expression",
        "mood", "moodboard", "quietness", "emptiness", "lighting", "shadow"
    }

    def is_visual_clean(phrase):
        tokens = re.findall(r"\b\w+\b", phrase.lower())
        return not any(t in abstract_terms for t in tokens)

    visuals_parsed = [v for v in parsed_data.get("visuals", []) if is_visual_clean(v)]
    visuals_json = [v for v in base.get("images_keywords", []) if is_visual_clean(v)]

    def get_base_tokens(phrase):
        return set(re.findall(r"\b\w+\b", phrase.lower()))

    selected_visuals = []
    candidate_pool = visuals_parsed + visuals_json
    import random
    random.shuffle(candidate_pool)

    for phrase in candidate_pool:
        current_tokens = get_base_tokens(phrase)
        if all(len(current_tokens.intersection(get_base_tokens(existing))) <= 1 for existing in selected_visuals):
            selected_visuals.append(phrase)
        if len(selected_visuals) >= 4:
            break

    base["all_images_keywords"] = candidate_pool
    base["images_keywords"] = selected_visuals if selected_visuals else ["texture shadow"]*4

    patterns = parsed_data.get("patterns", [])
    if patterns:
        base["pattern"] = patterns[0]

    # Defensive: ensure font_bg_color and font_color are valid hex
    def valid_hex(s):
        return isinstance(s, str) and re.match(r"^#[0-9a-fA-F]{6}$", s)
    if not valid_hex(base["font_bg_color"]):
        base["font_bg_color"] = "#FFFFFF"
    if not valid_hex(base["font_color"]):
        base["font_color"] = "#000000"

    # Map emotion to correct UI file from web_ui folder
    emotion_ui_mapping = {
        "JOY": "Joy_Ui.png",
        "HAPPINESS": "Joy_Ui.png", 
        "SORROW": "Sorrow_Ui.png",
        "DUSK": "Sorrow_Ui.png",
        "PEACE": "Peace_Ui.png",
        "SERENITY": "Peace_Ui.png",
        "LOVE": "Love_Ui.png",
        "ROMANCE": "Love_Ui.png",
        "FEAR": "Fear_Ui.png",
        "ANXIETY": "Fear_Ui.png",
        "TRUST": "Trust_Ui.png",
        "CONFIDENCE": "Trust_Ui.png",
        "SURPRISE": "Surprise_Ui.png",
        "WONDER": "Surprise_Ui.png",
        "POWER": "Power_Ui.png",
        "STRENGTH": "Power_Ui.png",
        "DISGUST": "Disgust_Ui.png",
        "REVULSION": "Disgust_Ui.png",
        "GUILT": "Guilt_Ui.png",
        "SHAME": "Guilt_Ui.png",
        "HOPE": "Hope_Ui.png",
        "OPTIMISM": "Hope_Ui.png",
        "NEUTRAL": "Neutral_Ui.png"
    }
    
    # Extract main emotion from label (e.g., "JOY/HAPPINESS" -> "JOY")
    main_emotion = label.split('/')[0].strip().upper()
    ui_filename = emotion_ui_mapping.get(main_emotion, "Neutral_Ui.png")
    base["website_ui"] = ui_filename

    print(f"Merged spec: {json.dumps(base, indent=2)}")
    return base

def tweak_assets(spec, new_data):
    for key in ['colors', 'visuals', 'patterns']:
        if new_data.get(key):
            spec[key] = list(set(spec.get(key, [])) | set(new_data[key]))
    return spec





def download_google_font(font_name):
    # TODO: Implement actual font download logic
    # For now, return a default font path
    return "arial.ttf"

def search_image(keyword, session_id):
    # TODO: Implement actual image search logic
    # For now, return a placeholder image path
    return "Blank Template.png"

def predict_emotion(parsed):
    return ""  #Ml model output

def generate_moodboard(parsed_data, emotion_label, session_id=None):
    import datetime
    import os
    import json
    from PIL import Image, ImageDraw, ImageFont, ImageOps
    import copy

    # Load emotion dataset
    with open("emotion_design_dataset.json", "r") as f:
        emotion_dataset = json.load(f)

    # Use provided session_id or generate a new one
    if session_id is None:
        session_id = "sess_" + datetime.datetime.now().strftime("%Y%m%d%H%M%S")

    # Merge prompt with emotion spec
    merged_spec = merge_prompt_with_spec(parsed_data, emotion_dataset, emotion_label)

    # Get font paths
    font_paths = font(emotion_label)
    merged_spec["font_paths"] = font_paths if font_paths else {
        "headings": "arial.ttf", "body_text": "arial.ttf", "highlight_text": "arial.ttf"
    }

    # IMPORTANT: Extract images from Pinterest/Pexels
    api_key = "Avn6UtTXyYNcle6Kr4J0o9fKEKt3BERVfCqxMUqOWoqIuyaHB25OsRt6"
    print("🔍 Starting image extraction...")
    merged_spec = image(merged_spec, emotion_label, api_key)
    print(f"📸 Image extraction complete. Paths: {merged_spec.get('image_paths', [])}")

    # Load template background
    template_bg = Image.open("Blank Template.png").convert("RGB")
    template_bg = template_bg.resize((1080, 1620))
    
    # Generate moodboard
    moodboard_img = moodboard(merged_spec, emotion_label, template_bg, emotion_dataset)
    
    # Save moodboard in Flask static directory for frontend access
    output_dir = os.path.join(os.path.dirname(__file__), "static", "moodboards")
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, f"{session_id}.png")
    moodboard_img.save(output_path)

    session_log = {
        "session_id": session_id,
        "timestamp": datetime.datetime.now().isoformat(),
        "prompt": parsed_data.get("prompt", ""),
        "emotion": emotion_label,
        "json_path": os.path.join(output_dir, f"moodboard_spec_{session_id}.json"),
        "image_paths": merged_spec.get("image_paths", []),
        "final_image_path": output_path
    }

    with open(session_log["json_path"], "w") as f:
        json.dump(merged_spec, f)

    return output_path, session_log

def font(emotion_label, dataset_path="emotion_design_dataset.json", out_dir="/tmp/fonts"):
    FALLBACK_FONT = "https://fonts.gstatic.com/s/opensans/v18/mem8YaGs126MiZpBA-UFVZ0bf8pkAg.woff2"
    GOOGLE_FONTS_API_KEY = "AIzaSyDLQF6akf8gCYgqkapFtNyosjmvxurqDAM"

    FONT_URL_OVERRIDES = {
        "Poppins": "https://fonts.gstatic.com/s/poppins/v20/pxiGyp8kv8JHgFVrJJfedw.woff2",
        "Open Sans": "https://fonts.gstatic.com/s/opensans/v18/mem8YaGs126MiZpBA-UFVZ0bf8pkAg.woff2"
    }

    def sanitize_font_filename(name):
        return "".join(c for c in name if c.isalnum()).lower()

    def sanitize_emotion_label(label):
        label = label.strip().upper()
        return re.sub(r'[\s\-_\/]+', '/', label)

    def build_fonts_service():
        return build("webfonts", "v1", developerKey=GOOGLE_FONTS_API_KEY)

    def fetch_font_url(font_name):
        if font_name in FONT_URL_OVERRIDES:
            return FONT_URL_OVERRIDES[font_name]
        try:
            service = build_fonts_service()
            fonts = service.webfonts().list().execute().get("items", [])
            for font in fonts:
                if font["family"].lower() == font_name.lower():
                    files = font.get("files", {})
                    return files.get("regular") or next((url for url in files.values() if ".ttf" in url.lower()), None)
        except Exception as e:
            print(f"Failed to fetch '{font_name}' from API: {e}")
        return None

    def download_font(name, url):
        slug = sanitize_font_filename(name)
        path = os.path.join(out_dir, f"{slug}.ttf")
        if os.path.exists(path):
            print(f"✔ Cached: {name} → {path}")
            return path
        try:
            os.makedirs(out_dir, exist_ok=True)
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            with open(path, "wb") as f:
                f.write(response.content)
            print(f"✔ Downloaded: {name} → {path}")
            return path
        except Exception as e:
            print(f"Download failed for '{name}': {e}")
            return FALLBACK_FONT

    def prepare(font_meta):
        font_paths = {}
        for role, meta in font_meta.items():
            font_name = meta.get("name")
            if not font_name:
                print(f"Missing font name for {role} — fallback used")
                font_paths[role] = FALLBACK_FONT
                continue
            print(f"Resolving font: {font_name} ({role})")
            font_url = fetch_font_url(font_name) or meta.get("url")
            font_paths[role] = download_font(font_name, font_url) if font_url else FALLBACK_FONT
        return font_paths

    # Main logic
    with open(dataset_path) as f:
        raw = json.load(f)
    dataset = {sanitize_emotion_label(k): v for k, v in raw.items()}
    label = sanitize_emotion_label(emotion_label)

    if label not in dataset:
        fallback = next((k for k in dataset if k.lower() == label.lower()), None)
        if fallback:
            label = fallback
            print(f"Using fallback label: {fallback}")
        else:
            print(f"Emotion label '{emotion_label}' not found")
            return {}

    font_meta = {}
    font_url_map = dataset[label].get("font_url", {})
    for role in ["headings", "body_text", "highlight_text"]:
        raw_label = dataset[label]["fonts"].get(role, "")
        font_name = raw_label.split(" (")[0].strip()
        if font_name:
            font_meta[role] = {
                "name": font_name,
                "url": font_url_map.get(font_name)
            }

    print(f"\nLoading fonts for: {label}")
    return prepare(font_meta)
    merged_spec = merge_prompt_with_spec(parsed_data, emotion_dataset, emotion_label)

    font_paths = {}
    for k, v in merged_spec["fonts"].items():
        font_paths[k] = download_google_font(v)
    merged_spec["font_paths"] = font_paths

    images = []
    for keyword in merged_spec.get("images_keywords", [])[:4]:
        img_path = search_image(keyword, session_id)
        if img_path:
            images.append(img_path)
    pattern_img = search_image(merged_spec["pattern"], session_id)
    merged_spec["image_paths"] = images
    merged_spec["pattern_path"] = pattern_img

    template_bg = Image.open("Blank Template.png").convert("RGB")
    template_bg = template_bg.resize((1080, 1620))
    moodboard = template_bg.copy()
    draw = ImageDraw.Draw(moodboard)


    raw_zones = [(0, 0, 535, 496), (551, 496, 529, 601), (804, 1271, 276, 349), (361, 1271, 423, 349)]
    image_zones = [(x, y, x + w, y + h) for (x, y, w, h) in raw_zones]
    image_paths = merged_spec["image_paths"]


    def paste_and_crop(img_path, target_box, canvas):
        img = Image.open(img_path).convert("RGB")
        img = ImageOps.fit(img, (target_box[2] - target_box[0], target_box[3] - target_box[1]), Image.Resampling.LANCZOS)
        canvas.paste(img, (target_box[0], target_box[1]))

    for zone, path in zip(image_zones, image_paths):
        paste_and_crop(path, zone, moodboard)

    color_zones = [(360 + 148 * i, 1120, 360 + 148 * i + 128, 1248) for i in range(5)]
    def get_hex_code(color):
        # If already a hex code, return as is
        if isinstance(color, str) and color.startswith("#") and len(color) == 7:
            return color
        # Try to find in colour.json
        color_lower = color.lower() if isinstance(color, str) else ""
        for hex_val, names in color_data.items():
            if color_lower in [n.lower() for n in names]:
                return hex_val
        # Fallback: return black if not found
        return "#000000"

    for zone, color in zip(color_zones, merged_spec["colors"]):
        hex_code = get_hex_code(color)
        try:
            rgb = tuple(int(hex_code.lstrip("#")[i:i+2], 16) for i in (0, 2, 4))
        except Exception:
            rgb = (0, 0, 0)
        draw.rectangle(zone, fill=rgb, outline="black")

        
    title_text = f"MOOD: {emotion_label.upper()}"
    title_font = ImageFont.truetype(merged_spec["font_paths"]["headings"], size=52)
    title_x = 265
    title_y = 540
    draw.text((title_x, title_y), title_text, fill="black", font=title_font)


    font_block_zone = (0, 628, 530, 1097)
    bg_rgb = tuple(int(merged_spec["font_bg_color"].lstrip("#")[i:i+2], 16) for i in (0, 2, 4))
    fg_rgb = tuple(int(merged_spec["font_color"].lstrip("#")[i:i+2], 16) for i in (0, 2, 4))
    draw.rectangle(font_block_zone, fill=bg_rgb)

    # Defensive check for 'samples' key
    if "samples" not in merged_spec:
        raise KeyError(f"'samples' key missing in merged_spec for emotion '{emotion_label}'. Available keys: {list(merged_spec.keys())}")
    samples = merged_spec["samples"]
    fonts = merged_spec["fonts"]

    y_cursor = font_block_zone[1] + 10
    for style in ["headings", "body_text", "highlight_text"]:
        descriptor = samples[style]
        label_font = ImageFont.truetype(merged_spec["font_paths"].get(style, merged_spec["font_paths"]["headings"]), size=15)
        sample_font = ImageFont.truetype(merged_spec["font_paths"].get(style, merged_spec["font_paths"]["headings"]), size=55)
        font_line = f"{fonts[style]} ({descriptor})"
        draw.text((font_block_zone[0] + 30, y_cursor), font_line, fill=fg_rgb, font=label_font)
        y_cursor += 30
        feeling_text = f"Feel The {emotion_label.upper()}"
        draw.text((font_block_zone[0] + 30, y_cursor), feeling_text, fill=fg_rgb, font=sample_font)
        y_cursor += 65

    # Save moodboard in Flask static directory for frontend access
    output_dir = os.path.join(os.path.dirname(__file__), "static", "moodboards")
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, f"{session_id}.png")
    moodboard.save(output_path)

    session_log = {
        "session_id": session_id,
        "timestamp": datetime.datetime.now().isoformat(),
        "prompt": parsed_data.get("prompt", ""),
        "emotion": emotion_label,
        "json_path": os.path.join(output_dir, f"moodboard_spec_{session_id}.json"),
        "image_paths": image_paths,
        "final_image_path": output_path
    }

    with open(session_log["json_path"], "w") as f:
        json.dump(merged_spec, f)

    # Optionally, return the output path or session log
    return output_path, session_log

def image(merged_spec, emotion_label, api_key, colour_json_path="colour.json", save_dir="images"):
    def build_color_lookup(path):
        with open(path, "r") as f:
            col = json.load(f)
        name2rgb, vocab = {}, set()
        for group in col.values():
            for name in group:
                try:
                    name2rgb[name] = ImageColor.getrgb(name)
                except:
                    continue
        for name in name2rgb:
            c = name.lower()
            vocab.update([c, c + "s", c + "es"])
            if c.endswith("y"):
                vocab.add(c[:-1] + "ies")
        vocab.update([
            "greys", "grays", "pinks", "blacks", "whites", "nudes", "pastels", "earthtones",
            "reds", "blues", "yells", "beiges", "greens", "oranges"
        ])
        rgb_norm = [tuple(c / 255 for c in name2rgb[name]) for name in name2rgb]
        tree = KDTree(rgb_norm)
        return tree, list(name2rgb.keys()), name2rgb, vocab

    def is_safe_image(src: str, alt: str) -> bool:
        src, alt = src.lower(), alt.lower()
        unsafe_keywords = [
            "cover", "thumbnail", "video", "youtube", "vimeo", "play button",
            "logo", "svg", "ad", "template", "banner", "product", "shop", "sale",
            "explicit", "provocative", "sensual", "lingerie", "nude", "sex"
        ]
        return not any(bad in src or bad in alt for bad in unsafe_keywords)

    def is_quality_image(src: str, alt: str, emotion_tags: list) -> bool:
        """Check if image meets quality and relevance criteria"""
        src, alt = src.lower(), alt.lower()
        
        # Prefer higher resolution images (474x or 736x are better quality on Pinterest)
        quality_indicators = ["474x", "736x", "564x"]
        has_quality = any(indicator in src for indicator in quality_indicators)
        
        # Check for relevance to emotion
        emotion_match = any(tag.lower() in f"{src} {alt}" for tag in emotion_tags)
        
        # Avoid low quality indicators
        low_quality = ["236x", "170x", "75x", "blur", "pixelated"]
        is_low_quality = any(indicator in src for indicator in low_quality)
        
        return has_quality or emotion_match and not is_low_quality

    def save_image(url, path):
        if "s.pinimg.com/webapp" in url:
            return False
        try:
            response = requests.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
            if "image" not in response.headers.get("Content-Type", ""):
                return False
            img = Image.open(BytesIO(response.content)).convert("RGB")
            img.save(path)
            return True
        except Exception as e:
            print(f"Failed to save image: {e}")
            return False

    def try_save_from_pool(urls, path):
        print(f"🔄 Trying to save image to {path} from {len(urls)} URLs...")
        for i, url in enumerate(urls):
            print(f"  📥 Attempting URL {i+1}: {url[:50]}...")
            if save_image(url, path):
                print(f"  ✅ Successfully saved image from URL {i+1}")
                return True
        print(f"  ❌ No good image found in pool of {len(urls)} URLs")
        return False

    def fetch_pinterest(phrase, color, emotion_label, count=8):
        options = Options()
        options.add_argument("--headless")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--remote-debugging-port=9222")
        
        # Windows Chrome paths - try common locations
        chrome_paths = [
            r"C:\Program Files\Google\Chrome\Application\chrome.exe",
            r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
            r"C:\Users\{}\AppData\Local\Google\Chrome\Application\chrome.exe".format(os.getenv('USERNAME')),
        ]
        
        chrome_found = False
        for chrome_path in chrome_paths:
            if os.path.exists(chrome_path):
                options.binary_location = chrome_path
                chrome_found = True
                print(f"🌐 Found Chrome at: {chrome_path}")
                break
        
        if not chrome_found:
            print("❌ Chrome not found on Windows. Skipping Pinterest...")
            return []
            
        options.add_argument("--window-size=1920,1080")
        options.add_argument("user-agent=Mozilla/5.0")

        driver = None
        try:
            service = ChromeService(ChromeDriverManager(chrome_type=ChromeType.GOOGLE).install())
            driver = webdriver.Chrome(service=service, options=options)
            print(f"✅ Chrome driver initialized successfully")
        except Exception as e:
            print(f"WebDriverManager failed: {e}")
            try:
                service = ChromeService()
                driver = webdriver.Chrome(service=service, options=options)
                print(f"✅ System chromedriver works")
            except Exception as fallback_e:
                print(f"System chromedriver fallback failed: {fallback_e}")
                return []

        emotion_tags = {
            "LOVE/BLUSH": ["romantic", "tender", "intimate", "cozy", "soft", "warm"],
            "JOY/HAPPINESS": ["bright", "cheerful", "vibrant", "colorful", "sunny", "positive"],
            "POWER/ANGER": ["bold", "strong", "dramatic", "intense", "dark", "powerful"],
            "PEACE/SERENITY": ["tranquil", "gentle", "calm", "peaceful", "natural", "serene"],
            "SORROW/DUSK": ["moody", "atmospheric", "dark", "melancholic", "grey", "subdued"],
            "SURPRISE/WONDER": ["colorful", "bright", "exciting", "dynamic", "vivid", "magical"],
            "TRUST/SECURITY": ["clean", "professional", "minimal", "structured", "reliable"],
            "FEAR/ANXIETY": ["dark", "moody", "atmospheric", "mysterious", "dramatic"],
            "NEUTRAL/CLARITY": ["clean", "minimal", "simple", "clear", "balanced"]
        }.get(emotion_label.upper(), ["aesthetic", "beautiful"])

        # Create more specific and relevant search query
        core_terms = phrase.replace(" ", "+")
        emotion_context = "+".join(emotion_tags[:3])  # Use top 3 emotion tags
        quality_terms = ["aesthetic", "beautiful", "high+quality"]
        
        # Combine for better relevance
        query_parts = [core_terms, emotion_context, "+".join(quality_terms)]
        if color and color != "gray":
            query_parts.append(color)
            
        query = "+".join(filter(None, query_parts))
        search_url = f"https://www.pinterest.com/search/pins/?q={query}"

        try:
            driver.get(search_url)
            time.sleep(4)  # Increased wait time for better loading
            
            # Scroll to load more images
            driver.execute_script("window.scrollTo(0, 1000);")
            time.sleep(2)
            
            images = []
            quality_images = []
            pins = driver.find_elements(By.TAG_NAME, "img")
            
            for pin in pins[:50]:  # Check more images for better selection
                try:
                    src = pin.get_attribute("src")
                    alt = (pin.get_attribute("alt") or "")
                    
                    if not src or "s.pinimg.com/webapp" in src:
                        continue
                    if not is_safe_image(src, alt):
                        continue
                    if any(c in f"{src} {alt}".lower() for c in color_vocab_all):
                        continue
                    
                    # Prioritize quality images
                    if is_quality_image(src, alt, emotion_tags):
                        quality_images.append(src)
                    else:
                        images.append(src)
                        
                except Exception as e:
                    continue
            
            # Return quality images first, then regular ones if needed
            final_images = quality_images[:count]
            if len(final_images) < count:
                final_images.extend(images[:count - len(final_images)])
                
            return final_images[:count]
            
        except Exception as e:
            print(f"Error scraping Pinterest: {e}")
            return []
        finally:
            if driver:
                driver.quit()

    def fetch_pexels(phrase, color, emotion_label, count=8):
        client = PexelsAPI(api_key)
        client.search(f"{phrase} {color} atmosphere", page=1, results_per_page=count)
        raw_entries = client.get_entries()
        safe_urls = [p.original for p in raw_entries if is_safe_image(p.original, getattr(p, "alt", ""))]
        return safe_urls[:count]

    def fetch_images(phrase, color, emotion_label, count=8):
        results = fetch_pinterest(phrase, color, emotion_label, count)
        if len(results) < count:
            print("Pinterest low yield → fallback to Pexels")
            results += fetch_pexels(phrase, color, emotion_label, count - len(results))
        return results[:count]

    tree, color_names, name2rgb, color_vocab_all = build_color_lookup(colour_json_path)
    os.makedirs(save_dir, exist_ok=True)

    keywords = merged_spec.get("images_keywords", [])[:4]
    colors = merged_spec.get("colors", [])[:5]
    pattern = merged_spec.get("pattern", "")
    
    # Ensure we have 4 keywords
    while len(keywords) < 4:
        keywords.append("texture shadow")
    
    # Handle colors - convert hex colors to color objects if needed
    color_objects = []
    for color in colors:
        if isinstance(color, str):
            if color.startswith("#"):
                # Convert hex to color object
                color_objects.append({"hex": color, "hue_group": "gray"})
            else:
                # Try to map color name to hue group
                color_lower = color.lower()
                if any(word in color_lower for word in ["red", "pink", "coral"]):
                    hue_group = "red"
                elif any(word in color_lower for word in ["blue", "sky", "navy"]):
                    hue_group = "blue"
                elif any(word in color_lower for word in ["green", "mint", "lime"]):
                    hue_group = "green"
                elif any(word in color_lower for word in ["yellow", "sunflower", "gold"]):
                    hue_group = "yellow"
                else:
                    hue_group = "gray"
                color_objects.append({"hex": "#CCCCCC", "hue_group": hue_group})
        elif isinstance(color, dict):
            color_objects.append(color)
        else:
            # Fallback
            color_objects.append({"hex": "#CCCCCC", "hue_group": "gray"})
    
    # Ensure we have at least 5 colors
    while len(color_objects) < 5:
        color_objects.append({"hex": "#CCCCCC", "hue_group": "gray"})
    
    colors = color_objects

    saved_paths = []

    print(f"🔍 Starting image search for {len(keywords)} keywords...")
    for i, phrase in enumerate(keywords):
        print(f"🖼️  Searching for image {i+1}: '{phrase}'")
        if color_objects and len(color_objects) > 0:
            color_obj = color_objects[random.randint(0, len(color_objects)-1)]
            color_name = color_obj.get("hue_group", "gray")
        else:
            color_name = "gray"
        print(f"   Using color context: {color_name}")
        
        urls = fetch_images(phrase, color_name, emotion_label, count=8)
        path = os.path.join(save_dir, f"keyword_{i+1}.jpg")
        
        if try_save_from_pool(urls, path):
            saved_paths.append(path)
            print(f"   ✅ Image {i+1} saved successfully")
        else:
            print(f"   ❌ Failed to get image {i+1}, using fallback")
            saved_paths.append("Blank Template.png")

    print(f"🎨 Searching for pattern image: '{pattern}'")
    if color_objects and len(color_objects) > 0:
        pattern_color_obj = color_objects[random.choice(range(min(3, len(color_objects))))]
        pattern_color = pattern_color_obj.get("hue_group", "gray")
    else:
        pattern_color = "gray"
    print(f"   Using pattern color: {pattern_color}")
    
    urls = fetch_images(pattern, pattern_color, emotion_label, count=8)
    pattern_path = os.path.join(save_dir, "pattern.jpg")
    
    if try_save_from_pool(urls, pattern_path):
        merged_spec["pattern_path"] = pattern_path
        print(f"   ✅ Pattern image saved successfully")
    else:
        merged_spec["pattern_path"] = "Blank Template.png"
        print(f"   ❌ Failed to get pattern image, using fallback")

    merged_spec["image_paths"] = saved_paths
    print(f"📸 Image extraction completed. Found {len([p for p in saved_paths if p != 'Blank Template.png'])} real images.")
    return merged_spec

def moodboard(spec, emotion_label, template_bg, emotion_dataset):
    # Ensure template is correct size
    if template_bg.size != (1080, 1620):
        template_bg = template_bg.resize((1080, 1620))

    # Ensure we have font paths - use fallback if missing
    font_paths = spec.get("font_paths", {})
    if not font_paths:
        font_paths = {"headings": "arial.ttf", "body_text": "arial.ttf", "highlight_text": "arial.ttf"}
        spec["font_paths"] = font_paths

    def get_fallback_font(size=18):
        try:
            return ImageFont.truetype("arial.ttf", size=size)
        except:
            return ImageFont.load_default()

    # Define zones for 1080x1620 output - reordered so top-left gets an image
    raw_zones = [
        (0, 0, 535, 496),      # TOP LEFT - now zone 0 (gets first image)
        (551, 496, 529, 601),  # Middle right - now zone 1
        (804, 1271, 276, 349), # Bottom - now zone 2  
        (361, 1271, 423, 349), # Bottom - now zone 3
        (0, 1120, 341, 500),   # Bottom left - now zone 4 (pattern)
        (551, 0, 529, 469)     # Top right - now zone 5 (UI)
    ]
    image_zones = [(x, y, x + w, y + h) for (x, y, w, h) in raw_zones]
    color_zones = [
        (360, 1120, 488, 1248),
        (508, 1120, 636, 1248),
        (656, 1120, 784, 1248),
        (804, 1120, 932, 1248),
        (952, 1120, 1080, 1248)
    ]
    font_block_zone = (0, 628, 530, 1097)  # Adjust if you need wider/narrower font area

    canvas = template_bg.copy()
    draw = ImageDraw.Draw(canvas)

    # Paste images
    def paste_and_crop(img_path, target_box, canvas):
        try:
            img = Image.open(img_path).convert("RGB")
            img = ImageOps.fit(
                img,
                (target_box[2] - target_box[0], target_box[3] - target_box[1]),
                Image.Resampling.LANCZOS
            )
            canvas.paste(img, (target_box[0], target_box[1]))
        except Exception as e:
            print(f"Failed to paste image '{img_path}': {e}")

    # Paste all 4 Pinterest images to their zones
    image_paths = spec.get("image_paths", [])
    for i, path in enumerate(image_paths):
        if i < len(image_zones) - 2:  # Leave space for pattern and UI
            paste_and_crop(path, image_zones[i], canvas)

    # Pattern goes to second-to-last zone
    pattern_path = spec.get("pattern_path")
    if pattern_path and os.path.exists(pattern_path):
        paste_and_crop(pattern_path, image_zones[-2], canvas)

    # Website UI goes to last zone
    ui_filename = spec.get("website_ui", "")
    ui_path = os.path.join("web_ui", ui_filename)
    if ui_filename and os.path.isfile(ui_path):
        paste_and_crop(ui_path, image_zones[-1], canvas)

    # Colors
    for zone, color_obj in zip(color_zones, spec.get("colors", [])):
        hex_code = color_obj["hex"] if isinstance(color_obj, dict) else color_obj
        try:
            rgb = tuple(int(hex_code.lstrip("#")[i:i+2], 16) for i in (0, 2, 4))
        except:
            rgb = (200, 200, 200)
        draw.rectangle(zone, fill=rgb)

    # Font block
    bg_rgb = tuple(int(spec["font_bg_color"].lstrip("#")[i:i+2], 16) for i in (0, 2, 4))
    fg_rgb = tuple(int(spec["font_color"].lstrip("#")[i:i+2], 16) for i in (0, 2, 4))
    draw.rectangle(font_block_zone, fill=bg_rgb)

    # Title Font
    main_title = emotion_label.upper()
    try:
        title_font_path = font_paths.get("headings", "arial.ttf")
        main_font = ImageFont.truetype(title_font_path, size=55)
    except Exception:
        main_font = get_fallback_font(size=55)
    title_bbox = draw.textbbox((0, 0), main_title, font=main_font)
    title_x = font_block_zone[0] + (font_block_zone[2] - font_block_zone[0]) // 2 - (title_bbox[2] - title_bbox[0]) // 2
    title_y = font_block_zone[1] - 110
    draw.text((title_x, title_y), main_title, fill="black", font=main_font)

    fonts = spec.get("fonts", {})
    samples = emotion_dataset.get(emotion_label, {}).get("samples", {})

    try:
        label_font_path = font_paths.get("body_text", "arial.ttf")
        label_font = ImageFont.truetype(label_font_path, size=18)
    except Exception:
        label_font = get_fallback_font(size=18)

    y_cursor = font_block_zone[1] + 32
    max_y = font_block_zone[3] - 40

    for style in ["headings", "body_text", "highlight_text"]:
        descriptor = samples.get(style, "").strip()
        font_name = fonts.get(style, "Unnamed")
        font_path = font_paths.get(style, font_paths.get("headings"))
        if not font_path:
            continue
        try:
            sample_font = ImageFont.truetype(font_path, size=60)
        except Exception:
            sample_font = get_fallback_font(size=60)

        label_line = f"{font_name} ({descriptor})" if descriptor else font_name
        label_bbox = draw.textbbox((0, 0), label_line, font=label_font)
        label_x = font_block_zone[0] + (font_block_zone[2] - font_block_zone[0]) // 2 - (label_bbox[2] - label_bbox[0]) // 2
        draw.text((label_x, y_cursor), label_line, fill=fg_rgb, font=label_font)
        y_cursor += label_bbox[3] - label_bbox[1] + 14

        emotion_key = emotion_label.split('/')[0].strip().capitalize()
        sample_line = f"Feel The {emotion_key}"
        sample_bbox = draw.textbbox((0, 0), sample_line, font=sample_font)
        sample_x = font_block_zone[0] + (font_block_zone[2] - font_block_zone[0]) // 2 - (sample_bbox[2] - sample_bbox[0]) // 2
        draw.text((sample_x, y_cursor), sample_line, fill=fg_rgb, font=sample_font)
        y_cursor += sample_bbox[3] - sample_bbox[1] + 30

        if y_cursor > max_y:
            break

    return canvas

def apply_user_overrides(user_prompt: str, visual_spec: dict) -> dict:
    prompt = user_prompt.lower()

    # Replace image keyword logic
    img_replace = re.findall(r'replace\s+(\w+)\s+with\s+(\w+)', prompt)
    for old_img, new_img in img_replace:
        for key, value in visual_spec.items():
            if value == old_img:
                visual_spec[key] = new_img
                print(f"Replaced image '{old_img}' with '{new_img}' in '{key}'.")

    # Color override
    hex_match = re.search(r'use this colour\s+(#[0-9a-fA-F]{6})', prompt)
    if hex_match:
        visual_spec["accent_color"] = hex_match.group(1)
        print(f"Accent color overridden to '{hex_match.group(1)}'.")

    # Use specific image
    visual_match = re.findall(r'use this visual\s+(\w+)', prompt)
    for new_visual in visual_match:
        visual_spec["main_img"] = new_visual
        print(f"🔧 Main visual replaced with '{new_visual}'.")

    # Emotion or tone prompts
    tone_map = {
        "calm": "#A2D5F2", "warm": "#FFB366", "bold": "#FF3E3E", "serene": "#B9E3C6",
        "playful": "#FFC8E4", "dramatic": "#222222"
    }
    for tone in tone_map:
        if f"make it more {tone}" in prompt or f"add {tone} tone" in prompt:
            visual_spec["accent_color"] = tone_map[tone]
            print(f"Emotional tone set to '{tone}' → Color: {tone_map[tone]}")

    # Exclude element
    exclude_match = re.findall(r'remove (\w+)', prompt)
    for element in exclude_match:
        for key in list(visual_spec.keys()):
            if visual_spec[key] == element or key == element:
                visual_spec.pop(key)
                print(f"Removed element '{element}' from spec.")

    # Include directive
    include_match = re.findall(r'include (\w+)', prompt)
    for asset in include_match:
        visual_spec[f"custom_{asset}"] = asset
        print(f"Included '{asset}' as 'custom_{asset}' in spec.")

    return visual_spec


# Ensure sanitize_emotion_label and is_prompt_generic are defined before run()
def sanitize_emotion_label(label):
    label = label.strip().upper()
    return re.sub(r'[\s\-_\/]+', '/', label)

def is_prompt_generic(parsed):
    visuals = parsed.get("visuals", [])
    patterns = parsed.get("patterns", [])
    colors = parsed.get("colors", [])
    if not visuals and not patterns and not colors:
        return True
    if sum([len(visuals) >= 1, len(colors) >= 1, len(patterns) >= 1]) >= 2:
        return False
    if len(visuals) == 0 and len(colors) <= 1 and len(patterns) == 0:
        return True
    return False

# Backend-safe stub for run_override_prompt
def run_override_prompt(spec, emotion_label, template_bg, emotion_dataset, session_dir, count=1):
    print("[run_override_prompt] Spec:")
    print(json.dumps(spec, indent=2))
    # You can add backend logic here to handle overrides via API, CLI, etc.

